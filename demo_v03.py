#!/usr/bin/env python3
"""
structured-agents v0.3.0 Demo

This demo demonstrates all core functionality of the structured-agents library:
- Tool protocol and GrailTool implementation
- ModelAdapter for model-specific behavior
- DecodingConstraint for grammar-constrained decoding
- AgentKernel for the core agent loop
- Agent as the high-level entry point
- Unified event system with Observer protocol
- LLMClient for API connections

The demo runs against a real vLLM server at remora-server:8000 with the Qwen model.
"""

import asyncio
import json
from pathlib import Path

from structured_agents.grammar.pipeline import (
    ConstraintPipeline,
    build_structural_tag_constraint,
)

# =============================================================================
# IMPORTS - All v0.3.0 Core Concepts
# =============================================================================

from structured_agents import (
    # Types
    Message,
    ToolCall,
    ToolResult,
    ToolSchema,
    TokenUsage,
    StepResult,
    RunResult,
    # Tools
    Tool,
    GrailTool,
    # Models
    ModelAdapter,
    QwenResponseParser,
    # Grammar
    DecodingConstraint,
    # Events
    Observer,
    NullObserver,
    Event,
    KernelStartEvent,
    KernelEndEvent,
    ModelRequestEvent,
    ModelResponseEvent,
    ToolCallEvent,
    ToolResultEvent,
    TurnCompleteEvent,
    # Core
    AgentKernel,
    Agent,
    AgentManifest,
    # Client
    LLMClient,
    OpenAICompatibleClient,
    build_client,
)


# =============================================================================
# STEP 1: Define Custom Grail Tool Scripts
# =============================================================================

# Tool scripts are defined as .pym files in demo_tools/ directory
# These will be loaded by the discover_tools function

DEMO_TOOLS_DIR = Path(__file__).parent / "demo_tools"


# =============================================================================
# STEP 2: Implement Tool Discovery (discovers .pym files)
# =============================================================================


def discover_tools(agents_dir: str) -> list[GrailTool]:
    """Discover and load .pym tools from a directory."""
    from grail import load, Limits

    tools = []
    tools_path = Path(agents_dir)

    if not tools_path.exists():
        print(f"  [discover_tools] Directory does not exist: {tools_path}")
        return []

    for pym_file in tools_path.glob("*.pym"):
        try:
            script = load(str(pym_file), limits=Limits.default())
            tool = GrailTool(script=script, limits=Limits.default())
            tools.append(tool)
            print(f"  [discover_tools] Loaded tool: {script.name}")
        except Exception as e:
            print(f"  [discover_tools] Failed to load {pym_file.name}: {e}")

    return tools


# =============================================================================
# STEP 3: Custom Event Observer
# =============================================================================


class DemoObserver:
    """Observer that prints events during agent execution."""

    async def emit(self, event: Event) -> None:
        if isinstance(event, KernelStartEvent):
            print(
                f"\n[KERNEL START] max_turns={event.max_turns}, tools={event.tools_count}"
            )
        elif isinstance(event, KernelEndEvent):
            print(
                f"[KERNEL END] turns={event.turn_count}, reason={event.termination_reason}"
            )
        elif isinstance(event, ModelRequestEvent):
            print(f"  [MODEL REQUEST] Turn {event.turn}: {event.model}")
        elif isinstance(event, ModelResponseEvent):
            print(
                f"  [MODEL RESPONSE] Turn {event.turn}: content={event.content[:50] if event.content else 'None'}..., tools={event.tool_calls_count}"
            )
        elif isinstance(event, ToolCallEvent):
            print(f"    [TOOL CALL] {event.tool_name}({json.dumps(event.arguments)})")
        elif isinstance(event, ToolResultEvent):
            status = "ERROR" if event.is_error else "OK"
            preview = event.output_preview[:30] if event.output_preview else ""
            print(f"    [TOOL RESULT] {event.tool_name}: {status} - {preview}...")
        elif isinstance(event, TurnCompleteEvent):
            print(
                f"  [TURN COMPLETE] Turn {event.turn}: {event.tool_calls_count} calls, {event.errors_count} errors"
            )


# =============================================================================
# STEP 4: Custom Model Adapter (demonstrates extensibility)
# =============================================================================


class DemoModelAdapter(ModelAdapter):
    """Custom adapter that demonstrates model-specific behavior."""

    def __init__(self, name: str = "qwen"):
        pipeline = ConstraintPipeline(
            builder=self._build_grammar,
            config=DecodingConstraint(
                strategy="structural_tag", allow_parallel_calls=True
            ),
        )
        super().__init__(
            name=name,
            response_parser=QwenResponseParser(),
            constraint_pipeline=pipeline,
        )

    @staticmethod
    def _build_grammar(
        tools: list[ToolSchema], config: DecodingConstraint
    ) -> dict | None:
        """Build grammar constraint for tool calls."""
        if not tools:
            return None

        print(f"  [GRAMMAR BUILDER] Building constraint for {len(tools)} tools")
        return build_structural_tag_constraint(tools, config)


# =============================================================================
# STEP 5: Demo - Direct Kernel Usage
# =============================================================================


async def demo_kernel_direct():
    """Demonstrate direct Kernel usage."""
    print("\n" + "=" * 60)
    print("DEMO 1: Direct AgentKernel Usage")
    print("=" * 60)

    # Discover tools
    print("\n[Step 1] Discovering tools...")
    tools = discover_tools(str(DEMO_TOOLS_DIR))
    print(f"  Found {len(tools)} tools: {[t.schema.name for t in tools]}")

    # Build client
    print("\n[Step 2] Building LLM client...")
    client = build_client(
        {
            "base_url": "http://remora-server:8000/v1",
            "api_key": "EMPTY",
            "model": "Qwen/Qwen3-4B-Instruct-2507-FP8",
            "timeout": 120.0,
        }
    )

    # Build adapter
    print("\n[Step 3] Building ModelAdapter...")
    adapter = DemoModelAdapter(name="qwen")

    # Build kernel
    print("\n[Step 4] Building AgentKernel...")
    kernel = AgentKernel(
        client=client,
        adapter=adapter,
        tools=tools,
        observer=DemoObserver(),
        max_tokens=1024,
        temperature=0.1,
    )

    # Create messages
    print("\n[Step 5] Creating messages...")
    messages = [
        Message(
            role="system", content="You are a helpful assistant with access to tools."
        ),
        Message(role="user", content="What is 5 + 3? Use the add tool."),
    ]

    # Run the kernel
    print("\n[Step 6] Running kernel...")
    tool_schemas = [t.schema for t in tools]
    result = await kernel.run(messages, tool_schemas, max_turns=3)

    # Print results
    print("\n[Results]")
    print(f"  Turn count: {result.turn_count}")
    print(f"  Termination: {result.termination_reason}")
    print(f"  Final message: {result.final_message.content}")
    print(f"  History length: {len(result.history)}")

    # Cleanup
    await kernel.close()

    return result


# =============================================================================
# STEP 6: Demo - Agent High-Level API
# =============================================================================


async def demo_agent_api():
    """Demonstrate the Agent high-level API."""
    print("\n" + "=" * 60)
    print("DEMO 2: Agent High-Level API")
    print("=" * 60)

    # For this demo, we'll create an in-memory agent without loading from bundle
    print("\n[Step 1] Building agent components...")

    tools = discover_tools(str(DEMO_TOOLS_DIR))
    print(f"  Tools: {[t.schema.name for t in tools]}")

    client = build_client(
        {
            "base_url": "http://remora-server:8000/v1",
            "api_key": "EMPTY",
            "model": "Qwen/Qwen3-4B-Instruct-2507-FP8",
        }
    )

    adapter = DemoModelAdapter()

    kernel = AgentKernel(
        client=client,
        adapter=adapter,
        tools=tools,
        observer=DemoObserver(),
    )

    # Create manifest
    manifest = AgentManifest(
        name="demo-agent",
        system_prompt="You are a helpful assistant with access to tools for math operations.",
        agents_dir=DEMO_TOOLS_DIR,
    )

    # Create agent
    agent = Agent(kernel=kernel, manifest=manifest)

    # Run agent
    print("\n[Step 2] Running agent...")
    result = await agent.run("What is 10 + 20? Use the add tool.")

    print("\n[Results]")
    print(f"  Turn count: {result.turn_count}")
    print(f"  Termination: {result.termination_reason}")
    print(f"  Final message: {result.final_message.content}")

    await agent.close()

    return result


# =============================================================================
# STEP 7: Demo - Event Types
# =============================================================================


async def demo_events():
    """Demonstrate the event system."""
    print("\n" + "=" * 60)
    print("DEMO 3: Event System")
    print("=" * 60)

    # Create some events
    events = [
        KernelStartEvent(max_turns=5, tools_count=3, initial_messages_count=2),
        ModelRequestEvent(turn=1, messages_count=3, tools_count=3, model="qwen"),
        ModelResponseEvent(
            turn=1, duration_ms=150, content="Hello", tool_calls_count=1, usage=None
        ),
        ToolCallEvent(
            turn=1, tool_name="add", call_id="call_123", arguments={"a": 1, "b": 2}
        ),
        ToolResultEvent(
            turn=1,
            tool_name="add",
            call_id="call_123",
            is_error=False,
            duration_ms=10,
            output_preview='{"sum": 3}',
        ),
        TurnCompleteEvent(
            turn=1, tool_calls_count=1, tool_results_count=1, errors_count=0
        ),
        KernelEndEvent(
            turn_count=1, termination_reason="no_tool_calls", total_duration_ms=200
        ),
    ]

    print("\n[Event Types]")
    for event in events:
        print(f"  {event.__class__.__name__}")

    # Demonstrate NullObserver
    print("\n[NullObserver Test]")
    null_obs = NullObserver()
    await null_obs.emit(
        KernelStartEvent(max_turns=1, tools_count=1, initial_messages_count=1)
    )
    print("  NullObserver works!")

    return events


# =============================================================================
# STEP 8: Demo - Grammar/Constraint Pipeline
# =============================================================================


def demo_grammar_pipeline():
    """Demonstrate the grammar constraint pipeline."""
    print("\n" + "=" * 60)
    print("DEMO 4: Grammar/Constraint Pipeline")
    print("=" * 60)

    # Create decoding constraint
    constraint = DecodingConstraint(
        strategy="ebnf",
        allow_parallel_calls=False,
        send_tools_to_api=False,
    )
    print(f"\n[DecodingConstraint]")
    print(f"  strategy: {constraint.strategy}")
    print(f"  allow_parallel_calls: {constraint.allow_parallel_calls}")
    print(f"  send_tools_to_api: {constraint.send_tools_to_api}")

    # Create pipeline with builder
    def grammar_builder(tools: list[ToolSchema], config: DecodingConstraint | None):
        if not tools:
            return None
        # In production, this would use xgrammar to build EBNF
        return {"grammar_mode": "ebnf", "tools": [t.name for t in tools]}

    pipeline = ConstraintPipeline(builder=grammar_builder, config=constraint)

    # Use pipeline
    tools = [
        ToolSchema(
            name="add", description="Add two numbers", parameters={"type": "object"}
        ),
        ToolSchema(
            name="multiply",
            description="Multiply two numbers",
            parameters={"type": "object"},
        ),
    ]

    result = pipeline.constrain(tools)
    print(f"\n[ConstraintPipeline]")
    print(f"  Result: {result}")

    # Empty tools case
    empty_result = pipeline.constrain([])
    print(f"  Empty tools result: {empty_result}")

    return pipeline


# =============================================================================
# STEP 9: Demo - Types and Core Classes
# =============================================================================


def demo_types():
    """Demonstrate core types."""
    print("\n" + "=" * 60)
    print("DEMO 5: Core Types")
    print("=" * 60)

    # Message
    msg = Message(role="user", content="Hello")
    print(f"\n[Message]")
    print(f"  role: {msg.role}")
    print(f"  content: {msg.content}")
    print(f"  to_openai_format(): {msg.to_openai_format()}")

    # ToolCall
    tc = ToolCall.create("add", {"a": 1, "b": 2})
    print(f"\n[ToolCall]")
    print(f"  id: {tc.id}")
    print(f"  name: {tc.name}")
    print(f"  arguments: {tc.arguments}")
    print(f"  arguments_json: {tc.arguments_json}")

    # ToolResult
    tr = ToolResult(call_id="call_123", name="add", output='{"sum": 3}', is_error=False)
    print(f"\n[ToolResult]")
    print(f"  call_id: {tr.call_id}")
    print(f"  name: {tr.name}")
    print(f"  output: {tr.output}")
    print(f"  is_error: {tr.is_error}")
    print(f"  to_message(): {tr.to_message()}")

    # ToolSchema
    ts = ToolSchema(
        name="add",
        description="Add two numbers",
        parameters={
            "type": "object",
            "properties": {"a": {"type": "int"}, "b": {"type": "int"}},
        },
    )
    print(f"\n[ToolSchema]")
    print(f"  name: {ts.name}")
    print(f"  description: {ts.description}")
    print(f"  parameters: {ts.parameters}")
    print(f"  to_openai_format(): {ts.to_openai_format()}")

    # TokenUsage
    usage = TokenUsage(prompt_tokens=100, completion_tokens=50, total_tokens=150)
    print(f"\n[TokenUsage]")
    print(f"  prompt_tokens: {usage.prompt_tokens}")
    print(f"  completion_tokens: {usage.completion_tokens}")
    print(f"  total_tokens: {usage.total_tokens}")

    return {
        "message": msg,
        "tool_call": tc,
        "tool_result": tr,
        "tool_schema": ts,
        "token_usage": usage,
    }


# =============================================================================
# STEP 10: Demo - Full Multi-Turn Conversation
# =============================================================================


async def demo_full_conversation():
    """Run a full multi-turn conversation with the agent."""
    print("\n" + "=" * 60)
    print("DEMO 6: Full Multi-Turn Conversation")
    print("=" * 60)

    tools = discover_tools(str(DEMO_TOOLS_DIR))

    client = build_client(
        {
            "base_url": "http://remora-server:8000/v1",
            "api_key": "EMPTY",
            "model": "Qwen/Qwen3-4B-Instruct-2507-FP8",
        }
    )

    adapter = DemoModelAdapter()

    kernel = AgentKernel(
        client=client,
        adapter=adapter,
        tools=tools,
        observer=DemoObserver(),
        max_tokens=1024,
    )

    # Multi-turn conversation
    messages = [
        Message(
            role="system", content="You are a helpful assistant. Use tools when needed."
        ),
        Message(role="user", content="Add 5 and 3, then multiply the result by 2."),
    ]

    tool_schemas = [t.schema for t in tools]

    print("\n[Running multi-turn conversation...]")
    result = await kernel.run(messages, tool_schemas, max_turns=5)

    print("\n[Final Results]")
    print(f"  Turns: {result.turn_count}")
    print(f"  Termination: {result.termination_reason}")
    print(f"  Final content: {result.final_message.content}")

    # Print conversation history
    print("\n[Conversation History]")
    for i, msg in enumerate(result.history):
        role = msg.role
        content = msg.content or ""
        if msg.tool_calls:
            content += f" [tool_calls: {len(msg.tool_calls)}]"
        print(f"  {i + 1}. {role}: {content[:60]}...")

    await kernel.close()

    return result


# =============================================================================
# MAIN
# =============================================================================


async def main():
    """Run all demos."""
    print("\n" + "#" * 60)
    print("# structured-agents v0.3.0 Demo")
    print("#" * 60)

    # Run demos
    demo_types()
    demo_grammar_pipeline()
    await demo_events()

    # These require the vLLM server
    try:
        await demo_kernel_direct()
    except Exception as e:
        print(f"\n[ERROR] Kernel demo failed: {e}")

    try:
        await demo_agent_api()
    except Exception as e:
        print(f"\n[ERROR] Agent demo failed: {e}")

    try:
        await demo_full_conversation()
    except Exception as e:
        print(f"\n[ERROR] Full conversation demo failed: {e}")

    print("\n" + "#" * 60)
    print("# Demo Complete!")
    print("#" * 60 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
